---
title: 'Homework 4: Functions and Tidy data'         
author: "Quentin D'Arcy"
date: "10/6/2020"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    theme: journal
    highlight: tango


---
```{r load_stuff, echo = FALSE, results = "hide" }
#I don't like how it looks with the full tidyverse output
# when it loads here, so I'm going to suppress the messages
options(tidyverse.quiet = TRUE)

#I'll do the same thing for the summarize() function so it doesn't
#report that it is ungrouping (again I don't like the look of it)
options(dplyr.summarise.inform = FALSE)

#load the tidyverse
library(tidyverse)


#load gt for pretty tables
library(gt)
```
# Question 1: Write a function for a single bootstrap from a given vector
```{r one_boot}

#Create a single bootstrap
one_boot <- function(boot_vec){
  
  #Sample based on the boot_vec parameters
 boot_ret <-  sample(boot_vec, size = length(boot_vec), replace = TRUE)

 #return the value
 return(boot_ret)
}

#Prove it works
my_vec = c(1,2,3,4,5,6,7,8,9,10)
one_boot(my_vec)

```
# Question 2: Given a vector, a request for some number of bootstraps (R), and a sample statistic function, return R number of values of that statistic. 

### Have R = 1000 the default and the function is mean. Show this works 
```{r many_boot}
#Create the function with an input vector, an R number of bootstraps, and the statistical function
boot_mean <- function(bootData, R = 1000, stat_func = mean){
  
  #Find the "statistic" of each boot and replicate it R number of times
  stat_vec <- replicate(R, stat_func(one_boot(bootData)))
  
  #Return the mean_vec
  return(stat_vec)
}

#Get 10 bootstrapped replicate draws of a mean from some vector
ten_boot <- boot_mean(my_vec, R = 10)
ten_boot
```

It looks like these values seem reasonable given our starting vector (a 1:10 vector). Here is a comparison between the mean of the 10 bootstrapped means and the mean of our starting vector:

<b>Ten bootstrap mean</b> : `r mean(ten_boot)`

<b>Mean of our starting vector</b>: `r mean(my_vec)`

Based on this the bootstrapped means seem reasonable

# Question 3: Given a vector, a request for some number of bootstraps, and a sample statistic function, return:

### 1) The original value of the statistic as applied to the vector
### 2) The mean of the statistic generated by the bootstrapped reps
### 3) The Upper/Lower 95% CI of the bootstrapped statistic (.025 and .975 quantile) 
### 4) The bias (the original value of the statistic - the mean of the bootstrapped statistic)

Here I'll be using mean as my sample statistic
```{r master_function}
#Create a function that accepts a vector, num of bootstraps, and a statistical function
analyze_data <- function(data_vec, boot_num = 1000, stat_func = mean){
  
  #Get the original mean
  original_stat <- stat_func(data_vec)
  
  #Get the bootstrapped mean
  strap_stat <- (boot_mean(data_vec,boot_num, stat_func))
  
  #Get the upper/lower 95% CI of the strap_mean
  upper_ci <- quantile(strap_stat, probs = .975)
  lower_ci <- quantile(strap_stat, probs = .025)
  
  #The bias
  data_bias <- original_stat - mean(strap_stat)
  
  #combine them in to a single return vector
  master_data = c(original_stat, stat_func(strap_stat), upper_ci, lower_ci, data_bias)
  
  #return that
  return(master_data)
}

fun_check <- analyze_data(my_vec, boot_num = 10)
fun_check
```

So, here is our data! (Again, using mean as our chosen statistic)

<b>Mean of the original data </b>: `r fun_check[1]`

<b>Mean of the bootstrapped means </b>: `r fun_check[2]`

<b>Upper 95% Confidence Interval of the bootstraps </b>: `r fun_check[3]`

<b>Lower 95% Confidence Interval of the bootstraps </b>: `r fun_check[4]`

<b>The Bias </b>: `r fun_check[5]`

# Set 4: FiveThirtyEight Poll data 
### 4a) Download and look at the data
```{r data_download}
#here for good practice
setwd(here::here())

#load our readr library
library(readr)

#read the .csv file with poll data
poll_data <- read_csv("data/president_polls.csv")

#View that data
library(visdat)
vis_dat(poll_data)

```

Here we can see this data is in Long format

### 4b) Get just the polling data for the week 9/29 to today
```{r recent_poll}
#load lubridate
library(lubridate)

#Find the polling data in question using lubridate
recent_poll <- poll_data %>%
  filter(answer %in% c('Trump', 'Biden'), mdy(start_date) >= mdy("9/29/20"))

#Check the new df
head(recent_poll)
```

### 4c) What's the bootstrapped average percentage for each candidate from nationwide polls
```{r avg_pct}
#Create a df for biden's national average
biden_avg <- recent_poll %>% 
  
  #Filter for all states (i.e., national) with the answer == Biden
  filter(state == "", answer == "Biden") %>% 
  
  #Summarize the average percent
  summarize(avg_pct = mean(boot_mean(recent_poll$pct)))

#Create a df for trump's national average
trump_avg <- recent_poll %>% 
  
  #Filter for all states (i.e., national) with the answer == Trump
  filter(state == "", answer == "Trump") %>% 
  
  #Find the bootstrapped average %
  summarize(avg_pct = mean(boot_mean(recent_poll$pct)))
```

Here we have Biden's average % (based on bootstraps): `r biden_avg`

Here we have Trump's average % (based on bootstraps): `r trump_avg`

### 4d) What is the average difference between the two candidates by state and national polls?
```{r avg_diff}
#create a df
avg_diff <- recent_poll %>% 
  
  #add on the unique id column
  mutate(unique_id = paste(question_id, poll_id, state, sep = " ")) %>% 
  
  #select just the columns we want
  select("unique_id","state","answer","pct") %>% 

  #switch to wide data using the values from the pct column and create
  #a "trump" and "biden" column
  pivot_wider(names_from = answer,
              values_from = pct) %>%
  
  #omit any rows with NA values
  na.omit() %>% 
  
  #calculate the difference between biden and trump
  group_by(state) %>% 
  
  #Add them as seperate columns
  mutate(biden_win_margin = mean(Biden - Trump),
         trump_win_margin = mean(Trump - Biden)) %>% 
  
  ungroup()
```

So unfortunately the data integrity that we receive in these polls is pretty low, so we have a fairly limited scope of data when you take in to account the time range (one week) and any data that had an NA value for state, answer, pct, or our unique_id.

The national polls show that there the country favors <b> Biden </b> by a bootstrapped average of `r biden_avg - trump_avg` %

All that being said, here's what we can say about the average difference between Trump and Biden per state

```{r win_margin}
gt(arrange(avg_diff, state)) %>% 
  #Set up the tab header
  tab_header(
    title = "Trump vs Biden Poll data",
    subtitle = "Data from 9/29/20 to 10/5/20") %>% 
  
  #Align it to the center
  opt_align_table_header(align = "center") %>% 
  
  #Label the columns
  cols_label(unique_id = "Collection/Poll/State",
             state = "State",
             Biden = "Biden (%)",
             Trump = "Trump (%)",
             biden_win_margin = "Average Biden Win Margin (%)",
             trump_win_margin = "Average Trump Win Margin (%)") %>% 
  
  #Stripe the rows to make it more readable
  opt_row_striping(row_striping = TRUE)
```

# Set 5) Replicating Matrices

### 5a) Using the mean and SD of Biden's national polling average, simulate 1000 draws from that population with a sample size of 50
```{r biden_sample}
#Find our national mean for Biden through the bootstrapped mean
mean_biden <-  mean(replicate(1000,
                              sample(recent_poll$pct,
                                     size = 50, 
                                     replace = TRUE)))

#Find our national sd for biden thorugh the bootstrapped sd
sd_biden <-  sd(replicate(1000,
                          sample(recent_poll$pct,
                                 size = 50,
                                 replace = TRUE)))

#Create a poplulation with n = 50 and those population parameters
sample_pop <- rnorm(n = 50, mean = mean_biden, sd = sd_biden)

#Simulate 1000 draws from that population using its size as the sample #size
biden_pop <- replicate(1000,
                       sample(sample_pop,
                              size = length(sample_pop),
                              replace = TRUE))
str(biden_pop)
```

So after simulating these 1000 draws from a population with an n of 50 we end up with a matrix that is 50x1000. Each row of this represents 1000 samples from the previously generated sample population (up to the sample size of 50). 

### 5b) Make it less ugly!
```{r elongate_it}
#Create a new data frame
long_biden_pop <- data.frame(biden_pop) %>% 
  
  #Pivot it longer making a column out of our individual sims
  #and our sim values
  pivot_longer(cols = everything(),
               names_to = "Sim",
               values_to = "Value")

long_biden_pop
```
By taking the previously wide data (50 sims at 1000 draws a piece) and turning it to long data, we create a table that is 2 columns and 50,000 rows long

### 5c) For each sim whats the bootstrapped mean and CI
```{r sim_boot}

#create a data frame
biden_straps <- long_biden_pop %>% 
  
  #Group by the sims
  group_by(Sim) %>% 
  
  #summarize down to just the Lower_CI, Upper_CI, and Mean
  summarize("Lower_CI" = quantile(Value, probs = .025),
            "Upper_CI" = quantile(Value, probs = .975),
            "Mean" = mean(Value))

#Here is our dataframe
biden_straps

#Here we will plot the mean incorporating CI infor with our
#ymin and ymax
biden_strap_plot<- ggplot(data = biden_straps,
                          mapping = aes(x = Sim,
                                        y = Mean,
                                        ymin = Lower_CI,
                                        ymax = Upper_CI))
#Set up a different theme
theme_set(theme_dark(base_size = 12))

#Here we will plot it so that each x value is a box plot of the #mean and the upper and lower CI
biden_strap_plot +

  geom_pointrange() +
  
  #Add the national average with a dashed line
  geom_hline(color = "red",
             yintercept = unlist(biden_avg)) +
  
  #Add the average of all bootstrapped means with a green        #line
  geom_hline(color = "green",
             yintercept = mean(biden_straps$Mean)) +
  
  #Add the average Upper CI as a dashed blue line
  geom_hline(color = "blue",
             yintercept = mean(biden_straps$Upper_CI)) +
  
  #Add the average Lower CI as a dashed blue line
  geom_hline(color = "blue",
             yintercept = mean(biden_straps$Lower_CI)) +
  
  #Label it
  labs(title = "Simulations of Biden's national average",
       subtitle = "Data collected from 9/29/20 to 10/5/20",
       x = "Simulation",
       y = "Biden's National Average (%)")
```

### 5d) What does this data mean?

So here we have all 1000 sims from our bootstrapped data. The data here is displayed as small box plots with the whiskers indicating the 95% CI for each of the 1000 sims.

However, because of the massive amount of data we are trying to describe here, the actual boxes are masked. To give a better idea of the values we are looking at I've included blue lines for the average upper and lower CIs, a red line that represents the national average from the original data, and a green line that represent the average of our simulated means

As we can see the bootstrapped mean `r mean(biden_straps$Mean)` and the national average `r biden_avg` are very close.

Additionally our SE of the bootstrapped mean `r sd(biden_straps$Mean)` shows that our polling data is decently precise.

By doing this analysis we can feel more confident in saying that Biden is losing in the polls taken between 9/29 and 10/5 than simply taking the average of the poll data (having analyzed the variance in the data and still come up with a similar result we know the average can be trusted)

#### DISCLAIMER: There are some data points within our tidy'd up table from 4d that seem to heavily swing the data towards Trump (i.e., the results from Alabama show a 20% higher voting rate for Trump than Biden). Because the "national" data that we took here is only from a few states, not the whole nation, values that are that far away from the average can really swing our overall results

#### In this case we have an external viability issue because of how limited our data is!